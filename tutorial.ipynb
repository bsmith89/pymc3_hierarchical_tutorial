{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and get familiar with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following to get the data\n",
    "\n",
    "```\n",
    "git clone https://github.com/bsmith89/statsclub_pymc3\n",
    "cd statsclub_pymc3\n",
    "make data/clean_data.tsv\n",
    "```\n",
    "\n",
    "We'll load this cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_table('data/clean_data.tsv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the distribution of radon measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = plt.hist(data.radon, bins=100)\n",
    "plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly a skewed distribution, and bounded at 0.\n",
    "\n",
    "We would normally think to log-transform these data, but we have a bunch of\n",
    "observations that were below the detection limit (0.1 of whatever units these measurements are in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.radon != 0].radon.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll replace those zeros with half of the detection limit, purely as a heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['radon_nonzero'] = data.radon\n",
    "data.radon_nonzero[data.radon == 0] = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that these data are approximately normally distributed.\n",
    "\n",
    "Much better for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "_ = plt.hist(data.radon_nonzero.apply(np.log), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_radon'] = data['radon_nonzero'].apply(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our analysis easier to manage, we'll start by just looking at measurements from Minnesota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data[data.state == 'MN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first factor that we're going to consider for predicting radon levels is\n",
    "where the measurement was taken.\n",
    "\n",
    "We know that radon comes out of the ground, so it makes sense that levels are\n",
    "higher in basements compared to the rest of a house.\n",
    "\n",
    "That's approximately what we see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('is_basement', 'log_radon', data=d, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.violinplot('is_basement', 'log_radon', data=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic linear model (Complete pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "\n",
    "y, x = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "n, r = x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "fit0 = sm.OLS(y, x).fit()\n",
    "\n",
    "fit0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jitter(x, perc=0.05):\n",
    "    span = max(x) - min(x)\n",
    "    return x + (np.random.rand(len(x)) - 0.5) * perc * span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(jitter(fit0.predict(), 0.1),\n",
    "            fit0.resid_pearson, s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['predict0'] = fit0.predict()\n",
    "d['resid0'] = d.predict0 - d.log_radon\n",
    "\n",
    "sns.violinplot('is_basement', 'resid0', data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(jitter(d['is_basement']), d['log_radon'], s=1)\n",
    "plt.plot([0, 1], [fit0.params[0], fit0.params[0] + fit0.params[1]], color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian version complete pooling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "\n",
    "with pm.Model() as model0:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r, 1))\n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    \n",
    "    mu = tt.dot(x.values, beta)\n",
    "    \n",
    "    obs = pm.Normal('obs', mu=mu, sd=sigma, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.logp(model0.test_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model0:\n",
    "    trace0 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No pooling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = d.state_county.unique()\n",
    "county_lookup = dict(zip(counties, range(len(counties))))\n",
    "d['county_idx'] = d.state_county.replace(county_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "\n",
    "with pm.Model() as model1:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    gamma = pm.Normal('gamma', sd=10, shape=(r2, 1))\n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma)\n",
    "    \n",
    "    obs = pm.Normal('obs', mu=mu, sd=sigma, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model1:\n",
    "    trace1 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace1, var_names=['beta', 'sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace1, var_names=['gamma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial pooling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "\n",
    "with pm.Model() as model2:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    \n",
    "    gamma_hyper_mean = pm.Normal('gamma_hyper_mean', sd=10)\n",
    "    gamma_hyper_sd = pm.HalfCauchy('gamma_hyper_sd', beta=2)\n",
    "    gamma = pm.Normal('gamma', mu=gamma_hyper_mean, sd=gamma_hyper_sd, shape=(r2, 1))\n",
    "    \n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma)\n",
    "    \n",
    "    obs = pm.Normal('obs', mu=mu, sd=sigma, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model2:\n",
    "    trace2 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace2, var_names=['beta', 'sigma', 'gamma_hyper_mean', 'gamma_hyper_sd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reparameterize partial pooling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "\n",
    "with pm.Model() as model3:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    \n",
    "    gamma_hyper_mean = pm.Normal('gamma_hyper_mean', sd=10)\n",
    "    gamma_hyper_sd = pm.HalfCauchy('gamma_hyper_sd', beta=2)\n",
    "    gamma_ = pm.Normal('gamma_', shape=(r2, 1))\n",
    "    gamma = pm.Deterministic('gamma', gamma_hyper_mean + gamma_hyper_sd * gamma_)\n",
    "    \n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "\n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma)\n",
    "    \n",
    "    obs = pm.Normal('obs', mu=mu, sd=sigma, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model3:\n",
    "    trace3 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace3, var_names=['beta', 'sigma', 'gamma_hyper_mean', 'gamma_hyper_sd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add county-level uranium as predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "_u = d[['state_county', 'county_uranium']].drop_duplicates()\n",
    "_u['state_county'] = _u.state_county.map(lambda x: 'state_county[' + x + ']')\n",
    "_u = _u.set_index('state_county')\n",
    "_u = _u.loc[x2.columns]\n",
    "u = patsy.dmatrix('county_uranium', data=_u, return_type='dataframe')\n",
    "r3 = u.shape[1]\n",
    "\n",
    "\n",
    "assert np.all(u.index == x2.columns)\n",
    "\n",
    "\n",
    "with pm.Model() as model4:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    \n",
    "    gamma_hyper_beta = pm.Normal('gamma_hyper_beta', sd=10, shape=(r3, 1))\n",
    "    gamma_hyper_mu = pm.Deterministic('gamma_hyper_mu', tt.dot(u.values, gamma_hyper_beta))\n",
    "    gamma_hyper_sd = pm.HalfCauchy('gamma_hyper_sd', beta=2)\n",
    "    gamma_ = pm.Normal('gamma_', shape=(r2, 1))\n",
    "    gamma = pm.Deterministic('gamma', gamma_hyper_mu + gamma_ * gamma_hyper_sd)\n",
    "    \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma)\n",
    "\n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    obs = pm.Normal('obs', mu=mu, sd=sigma, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model4:\n",
    "    trace4 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace4,\n",
    "             var_names=['beta', 'gamma_hyper_beta0',\n",
    "                        'gamma_hyper_beta', 'gamma_hyper_sd',\n",
    "                        'sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace4, var_names=['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace4.gamma_hyper_mu.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.05, 0.25, 0.5, 0.75, 0.95]\n",
    "gamma_dist_prd = pd.DataFrame(np.quantile(trace4.gamma_hyper_mu, quantiles, axis=0).T[0],\n",
    "                              columns=quantiles, index=counties)\n",
    "gamma_dist_obs = pd.DataFrame(np.quantile(trace4.gamma, quantiles, axis=0).T[0],\n",
    "                              columns=quantiles, index=counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(gamma_dist_prd[0.5], gamma_dist_obs[0.5])\n",
    "plt.vlines(gamma_dist_prd[0.5], gamma_dist_obs[0.25], gamma_dist_obs[0.75], lw=0.5)\n",
    "plt.hlines(gamma_dist_obs[0.5], gamma_dist_prd[0.25], gamma_dist_prd[0.75], lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a random slope term by county without pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "_u = d[['state_county', 'county_uranium']].drop_duplicates()\n",
    "_u['state_county'] = _u.state_county.map(lambda x: 'state_county[' + x + ']')\n",
    "_u = _u.set_index('state_county')\n",
    "_u = _u.loc[x2.columns]\n",
    "u = patsy.dmatrix('county_uranium', data=_u, return_type='dataframe')\n",
    "r3 = u.shape[1]\n",
    "\n",
    "\n",
    "assert np.all(u.index == x2.columns)\n",
    "\n",
    "\n",
    "with pm.Model() as model5:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    \n",
    "    gamma_hyper_beta = pm.Normal('gamma_hyper_beta', sd=10, shape=(r3, 1))\n",
    "    gamma_hyper_mu = pm.Deterministic('gamma_hyper_mu', tt.dot(u.values, gamma_hyper_beta))\n",
    "    gamma_hyper_sd = pm.HalfCauchy('gamma_hyper_sd', beta=2)\n",
    "    gamma_ = pm.Normal('gamma_', shape=(r2, 1))\n",
    "    gamma = pm.Deterministic('gamma', gamma_hyper_mu + gamma_ * gamma_hyper_sd)\n",
    "    \n",
    "    kappa = pm.Normal('kappa', sd=10, shape=(r2, 1))\n",
    "    \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma) + tt.dot(x1.values * x2.values, kappa)\n",
    "\n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    obs = pm.Normal('obs', mu=mu, sd=sigma, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model5:\n",
    "    trace5 = pm.sample(tune=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace5, var_names=['beta',\n",
    "                                'gamma_hyper_beta', 'gamma_hyper_sd',\n",
    "                                'sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace5, var_names=['kappa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -200\n",
    "\n",
    "mu_expect5 = mu.eval({getattr(model5, k.name): trace5[i][k.name]\n",
    "                      for k in model5.vars\n",
    "                      if k.name not in ['sigma_log__']})\n",
    "plt.scatter(mu_expect5, y.values)\n",
    "plt.plot([0, 2], [0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(trace5['gamma_hyper_beta'][:,0,0],\n",
    "            trace5['gamma_hyper_beta'][:,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace5.varnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a random slope term by county with partial pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "_u = d[['state_county', 'county_uranium']].drop_duplicates()\n",
    "_u['state_county'] = _u.state_county.map(lambda x: 'state_county[' + x + ']')\n",
    "_u = _u.set_index('state_county')\n",
    "_u = _u.loc[x2.columns]\n",
    "u = patsy.dmatrix('county_uranium', data=_u, return_type='dataframe')\n",
    "r3 = u.shape[1]\n",
    "\n",
    "\n",
    "assert np.all(u.index == x2.columns)\n",
    "\n",
    "\n",
    "with pm.Model() as model6:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    \n",
    "    gamma_hyper_beta = pm.Normal('gamma_hyper_beta', sd=10, shape=(r3, 1))\n",
    "    gamma_hyper_mu = pm.Deterministic('gamma_hyper_mu', tt.dot(u.values, gamma_hyper_beta))\n",
    "    gamma_hyper_sd = pm.HalfCauchy('gamma_hyper_sd', beta=2)\n",
    "    gamma_ = pm.Normal('gamma_', shape=(r2, 1))\n",
    "    gamma = pm.Deterministic('gamma', gamma_hyper_mu + gamma_ * gamma_hyper_sd)\n",
    "    \n",
    "    kappa_hyper_beta = pm.Normal('kappa_hyper_beta', sd=10, shape=(r3, 1))\n",
    "    kappa_hyper_mu = pm.Deterministic('kappa_hyper_mu', tt.dot(u.values, kappa_hyper_beta))\n",
    "    kappa_hyper_sd = pm.HalfCauchy('kappa_hyper_sd', beta=2)\n",
    "    kappa_ = pm.Normal('kappa_', shape=(r2, 1))\n",
    "    kappa = pm.Deterministic('kappa', kappa_hyper_mu + kappa_ * kappa_hyper_sd)\n",
    "    \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma) + tt.dot(x1.values * x2.values, kappa)\n",
    "\n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    obs = pm.Normal('obs', mu=mu, sd=sigma, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model6:\n",
    "    trace6 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace6, var_names=['beta',\n",
    "                                'gamma_hyper_beta', 'gamma_hyper_sd',\n",
    "                                'sigma', 'kappa_hyper_beta', 'kappa_hyper_sd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace6, var_names=['kappa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_traces = {\n",
    "                     model0: trace0,    # 0\n",
    "                     model1: trace1,    # 1\n",
    "                     model2: trace2,    # 2\n",
    "                     model3: trace3,    # 3\n",
    "                     model4: trace4,    # 4\n",
    "                     model5: trace5,    # 5\n",
    "                     model6: trace6,    # 6\n",
    "                     }\n",
    "\n",
    "pm.compare(models_and_traces, ic='WAIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model6:\n",
    "    ppc6 = pd.DataFrame(pm.sample_posterior_predictive(trace6, samples=1)['obs'][0],\n",
    "                        index=y.index, columns=y.columns)\n",
    "    \n",
    "plt.scatter(ppc6.log_radon, y.log_radon, s=2)\n",
    "plt.plot([-1, 4], [-1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "_u = d[['state_county', 'county_uranium']].drop_duplicates()\n",
    "_u['state_county'] = _u.state_county.map(lambda x: 'state_county[' + x + ']')\n",
    "_u = _u.set_index('state_county')\n",
    "_u = _u.loc[x2.columns]\n",
    "u = patsy.dmatrix('county_uranium', data=_u, return_type='dataframe')\n",
    "r3 = u.shape[1]\n",
    "\n",
    "\n",
    "assert np.all(u.index == x2.columns)\n",
    "\n",
    "\n",
    "with pm.Model() as model7:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    \n",
    "    gamma_hyper_beta = pm.Normal('gamma_hyper_beta', sd=10, shape=(r3, 1))\n",
    "    gamma_hyper_mu = pm.Deterministic('gamma_hyper_mu', tt.dot(u.values, gamma_hyper_beta))\n",
    "    gamma_hyper_sd = pm.HalfCauchy('gamma_hyper_sd', beta=2)\n",
    "    gamma_ = pm.Normal('gamma_', shape=(r2, 1))\n",
    "    gamma = pm.Deterministic('gamma', gamma_hyper_mu + gamma_ * gamma_hyper_sd)\n",
    "    \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma)\n",
    "\n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    nu = pm.HalfCauchy('nu', beta=2)\n",
    "    obs = pm.StudentT('obs', mu=mu, sigma=sigma, nu=nu, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model7:\n",
    "    trace7 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace7, var_names=['beta',\n",
    "                                'gamma_hyper_beta', 'gamma_hyper_sd',\n",
    "                                'sigma', 'nu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model7:\n",
    "    ppc7 = pd.DataFrame(pm.sample_posterior_predictive(trace7, samples=1)['obs'][0],\n",
    "                        index=y.index, columns=y.columns)\n",
    "    \n",
    "plt.scatter(ppc7.log_radon, y.log_radon, s=2)\n",
    "plt.plot([-1, 4], [-1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_traces = {\n",
    "                     model0: trace0,    # 0\n",
    "                     model1: trace1,    # 1\n",
    "                     model2: trace2,    # 2\n",
    "                     model3: trace3,    # 3\n",
    "                     model4: trace4,    # 4\n",
    "                     model5: trace5,    # 5\n",
    "                     model6: trace6,    # 6\n",
    "                     model7: trace7,    # 6\n",
    "                     }\n",
    "\n",
    "pm.compare(models_and_traces, ic='WAIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "_u = d[['state_county', 'county_uranium']].drop_duplicates()\n",
    "_u['state_county'] = _u.state_county.map(lambda x: 'state_county[' + x + ']')\n",
    "_u = _u.set_index('state_county')\n",
    "_u = _u.loc[x2.columns]\n",
    "u = patsy.dmatrix('county_uranium', data=_u, return_type='dataframe')\n",
    "r3 = u.shape[1]\n",
    "\n",
    "\n",
    "assert np.all(u.index == x2.columns)\n",
    "\n",
    "\n",
    "with pm.Model() as model8:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    \n",
    "    gamma_hyper_beta = pm.Normal('gamma_hyper_beta', sd=10, shape=(r3, 1))\n",
    "    gamma_hyper_mu = pm.Deterministic('gamma_hyper_mu', tt.dot(u.values, gamma_hyper_beta))\n",
    "    gamma_hyper_sd = pm.HalfCauchy('gamma_hyper_sd', beta=2)\n",
    "    gamma_ = pm.Normal('gamma_', shape=(r2, 1))\n",
    "    gamma = pm.Deterministic('gamma', gamma_hyper_mu + gamma_ * gamma_hyper_sd)\n",
    "    \n",
    "    kappa_hyper_beta = pm.Normal('kappa_hyper_beta', sd=10, shape=(r3, 1))\n",
    "    kappa_hyper_mu = pm.Deterministic('kappa_hyper_mu', tt.dot(u.values, kappa_hyper_beta))\n",
    "    kappa_hyper_sd = pm.HalfCauchy('kappa_hyper_sd', beta=2)\n",
    "    kappa_ = pm.Normal('kappa_', shape=(r2, 1))\n",
    "    kappa = pm.Deterministic('kappa', kappa_hyper_mu + kappa_ * kappa_hyper_sd)\n",
    "    \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma) + tt.dot(x1.values * x2.values, kappa)\n",
    "\n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    nu = pm.HalfCauchy('nu', beta=2)\n",
    "    obs = pm.StudentT('obs', mu=mu, sigma=sigma, nu=nu, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model8:\n",
    "    trace8 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_traces = {\n",
    "                     model0: trace0,    # 0\n",
    "                     model1: trace1,    # 1\n",
    "                     model2: trace2,    # 2\n",
    "                     model3: trace3,    # 3\n",
    "                     model4: trace4,    # 4\n",
    "                     model5: trace5,    # 5\n",
    "                     model6: trace6,    # 6\n",
    "                     model7: trace7,    # 7\n",
    "                     model8: trace8,    # 8\n",
    "                     }\n",
    "\n",
    "pm.compare(models_and_traces, ic='WAIC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}