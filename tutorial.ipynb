{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Modeling in PyMC3\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Remixed from <https://docs.pymc.io/notebooks/multilevel_modeling.html>.\n",
    "\n",
    "My goals for this tutorial are to:\n",
    "\n",
    "- (Re)Introduce hierarchical modeling\n",
    "- Demo PyMC3\n",
    "- Convince you of the flexibility of statistical modeling in the Bayesian framework\n",
    "- Give you some general tools for multi-level modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install all of the necessary packages.\n",
    "\n",
    "E.g.\n",
    "\n",
    "```bash\n",
    "conda create -n bhm --file requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following to get the repository and data\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/bsmith89/pymc3_hierarchical_tutorial\n",
    "cd pymc3_hierarchical_tutorial\n",
    "conda activate bhm\n",
    "make data/clean_data.tsv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and get familiar with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load this cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_table('data/clean_data.tsv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of radon measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(data.radon, bins=100)\n",
    "plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly a skewed distribution, and bounded at 0.\n",
    "\n",
    "We would normally think to log-transform these data, but we have a bunch of\n",
    "observations that were below the detection limit (0.1 of whatever units these measurements are in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.radon != 0].radon.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll replace those zeros with half of the detection limit, purely as a heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['radon_nonzero'] = data.radon\n",
    "data.radon_nonzero[data.radon == 0] = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that these data are approximately normally distributed.\n",
    "\n",
    "Much better for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "_ = plt.hist(data.radon_nonzero.apply(np.log), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_radon'] = data['radon_nonzero'].apply(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our analysis easier to manage, we'll start by just looking at measurements from Minnesota, only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting radon measurements in MN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data[data.state == 'MN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first factor that we're going to consider for predicting radon levels is\n",
    "where the measurement was taken.\n",
    "\n",
    "We know that radon comes out of the ground, so it makes sense that levels are\n",
    "higher in basements compared to the rest of a house.\n",
    "\n",
    "That's approximately what we see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter('is_basement', 'log_radon', data=d, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.violinplot('is_basement', 'log_radon', data=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classic linear model (Complete pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start by taking a standard, linear regression approach to analyzing these data.\n",
    "\n",
    "Since we expect measurements taken in the basement to be higher, we can start by\n",
    "modeling this using OLS and the following formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "\n",
    "y, x = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "n, r = x.shape\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using the package `patsy` to build my design matrices, because it\n",
    "gives me convenient \"R-like\" formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "fit0 = sm.OLS(y, x).fit()\n",
    "\n",
    "fit0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This linear regression shows us that, indeed, measurements\n",
    "taken in the basement are higher than in other parts of the house.\n",
    "\n",
    "With our relatively large sample size, our p-value is VERY significant,\n",
    "even though the R^2 is quite small.\n",
    "\n",
    "It's worth doing a few standard diagnostics to make sure this model is\n",
    "appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jitter(x, perc=0.05):\n",
    "    span = max(x) - min(x)\n",
    "    return x + (np.random.rand(len(x)) - 0.5) * perc * span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(jitter(fit0.predict(), 0.1),\n",
    "            fit0.resid_pearson, s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_df = pd.DataFrame({'is_basement': d.is_basement, 'resid': fit0.resid_pearson})\n",
    "\n",
    "sns.violinplot('is_basement', 'resid', data=resid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(jitter(d['is_basement']), d['log_radon'], s=1)\n",
    "plt.plot([0, 1], [fit0.params[0], fit0.params[0] + fit0.params[1]], color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model fits the data.\n",
    "\n",
    "However, we know that the basic assumptions of this linear regression (**I**ID) is violated.\n",
    "\n",
    "Since these data are geographically distributed, i.e. by county, they are not independent.\n",
    "Some regions may have higher or lower radon levels on average.\n",
    "This is consistent with the fact that we know radon is a product of uranium decay, and\n",
    "uranium levels vary across Minnesota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear model with county effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x = patsy.dmatrices('log_radon ~ 0 + state_county + is_basement', data=d, return_type='dataframe')\n",
    "n, r = x.shape\n",
    "\n",
    "fit1 = sm.OLS(y, x).fit()\n",
    "fit1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(fit1.predict(),\n",
    "            y, s=0.5)\n",
    "plt.plot([0, 3], [0, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works pretty well!\n",
    "\n",
    "There are, however, two problems with this model.\n",
    "\n",
    "The biggest is that the estimates for county effects are basically independent,\n",
    "and reflect a simple county mean.\n",
    "This is problematic, because some counties might have very few observations,\n",
    "and there coefficients will not be a good estimate for the county-level expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.groupby('state_county').apply(len).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to solve this problem using a hierarchical model, and we're going\n",
    "to build our model under a Bayesian framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian clone of OLS\n",
    "\n",
    "But first I need to introduce PyMC3 and show how to use it.\n",
    "\n",
    "I'll therefore start by building the above models with PyMC3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete pooling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "\n",
    "with pm.Model() as model_classic:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r, 1))\n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    \n",
    "    mu = tt.dot(x.values, beta)\n",
    "    \n",
    "    obs = pm.Normal('obs', mu=mu, sd=sigma, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classic.logp(model_classic.test_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_classic:\n",
    "    trace_classic = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_classic:\n",
    "    ppc_classic = pd.DataFrame(pm.sample_posterior_predictive(trace_classic, samples=1)['obs'][0],\n",
    "                        index=y.index, columns=y.columns)\n",
    "    \n",
    "plt.scatter(ppc_classic.log_radon, y.log_radon, s=2)\n",
    "plt.plot([-1, 4], [-1, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model flexibility - substituting in the t-distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model0:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r, 1))\n",
    "    \n",
    "    mu = tt.dot(x.values, beta)\n",
    "    \n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    nu = pm.HalfCauchy('nu', beta=2)\n",
    "    obs = pm.StudentT('obs', mu=mu, sigma=sigma, nu=nu, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.logp(model0.test_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model0:\n",
    "    trace0 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model0:\n",
    "    ppc0 = pd.DataFrame(pm.sample_posterior_predictive(trace0, samples=1)['obs'][0],\n",
    "                        index=y.index, columns=y.columns)\n",
    "    \n",
    "plt.scatter(ppc0.log_radon, y.log_radon, s=2)\n",
    "plt.plot([-1, 4], [-1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "                     ('complete_pooling_normal', model_classic, trace_classic),\n",
    "                     ('complete_pooling', model0, trace0),\n",
    "         ]\n",
    "\n",
    "\n",
    "\n",
    "model_compare = pm.compare({x[1]: x[2] for x in models}, ic='LOO')\n",
    "model_compare.rename(index={i: x[0] for i, x in enumerate(models)}, inplace=True)\n",
    "model_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No pooling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = d.state_county.unique()\n",
    "county_lookup = dict(zip(counties, range(len(counties))))\n",
    "d['county_idx'] = d.state_county.replace(county_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "\n",
    "with pm.Model() as model1:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    gamma = pm.Normal('gamma', sd=10, shape=(r2, 1))\n",
    "    \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma)\n",
    "    \n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    nu = pm.HalfCauchy('nu', beta=2)\n",
    "    obs = pm.StudentT('obs', mu=mu, sigma=sigma, nu=nu, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model1:\n",
    "    trace1 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace1, var_names=['beta', 'sigma', 'nu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace1, var_names=['gamma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random effects with partial pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "\n",
    "with pm.Model() as model2:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    \n",
    "    gamma_hyper_mean = pm.Normal('gamma_hyper_mean', sd=10)\n",
    "    gamma_hyper_sd = pm.HalfCauchy('gamma_hyper_sd', beta=2)\n",
    "    gamma = pm.Normal('gamma', mu=gamma_hyper_mean, sd=gamma_hyper_sd, shape=(r2, 1))\n",
    "        \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma)\n",
    "    \n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    nu = pm.HalfCauchy('nu', beta=2)\n",
    "    obs = pm.StudentT('obs', mu=mu, sigma=sigma, nu=nu, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model2:\n",
    "    trace2 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace2, var_names=['beta', 'gamma_hyper_mean', 'gamma_hyper_sd', 'sigma', 'nu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reparameterize partial pooling model (Noncentered reparameterization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "\n",
    "with pm.Model() as model3:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    \n",
    "    gamma_hyper_mean = pm.Normal('gamma_hyper_mean', sd=10)\n",
    "    gamma_hyper_sd = pm.HalfCauchy('gamma_hyper_sd', beta=2)\n",
    "    gamma_ = pm.Normal('gamma_', shape=(r2, 1))\n",
    "    gamma = pm.Deterministic('gamma', gamma_hyper_mean + gamma_hyper_sd * gamma_)\n",
    "    \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma)\n",
    "    \n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    nu = pm.HalfCauchy('nu', beta=2)\n",
    "    obs = pm.StudentT('obs', mu=mu, sigma=sigma, nu=nu, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model3:\n",
    "    trace3 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace3, var_names=['beta', 'gamma_hyper_mean', 'gamma_hyper_sd', 'sigma', 'nu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add county-level uranium as predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "_u = d[['state_county', 'county_uranium']].drop_duplicates()\n",
    "_u['state_county'] = _u.state_county.map(lambda x: 'state_county[' + x + ']')\n",
    "_u = _u.set_index('state_county')\n",
    "_u = _u.loc[x2.columns]\n",
    "u = patsy.dmatrix('county_uranium', data=_u, return_type='dataframe')\n",
    "r3 = u.shape[1]\n",
    "\n",
    "\n",
    "assert np.all(u.index == x2.columns)\n",
    "\n",
    "\n",
    "with pm.Model() as model4:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    \n",
    "    gamma_hyper_beta = pm.Normal('gamma_hyper_beta', sd=10, shape=(r3, 1))\n",
    "    gamma_hyper_mu = pm.Deterministic('gamma_hyper_mu', tt.dot(u.values, gamma_hyper_beta))\n",
    "    gamma_hyper_sd = pm.HalfCauchy('gamma_hyper_sd', beta=2)\n",
    "    gamma_ = pm.Normal('gamma_', shape=(r2, 1))\n",
    "    gamma = pm.Deterministic('gamma', gamma_hyper_mu + gamma_ * gamma_hyper_sd)\n",
    "    \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma)\n",
    "\n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    nu = pm.HalfCauchy('nu', beta=2)\n",
    "    obs = pm.StudentT('obs', mu=mu, sigma=sigma, nu=nu, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model4:\n",
    "    trace4 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace4,\n",
    "             var_names=['beta', 'gamma_hyper_beta0',\n",
    "                        'gamma_hyper_beta', 'gamma_hyper_sd',\n",
    "                        'sigma', 'nu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace4, var_names=['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace4.gamma_hyper_mu.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.05, 0.25, 0.5, 0.75, 0.95]\n",
    "gamma_dist_prd = pd.DataFrame(np.quantile(trace4.gamma_hyper_mu, quantiles, axis=0).T[0],\n",
    "                              columns=quantiles, index=counties)\n",
    "gamma_dist_obs = pd.DataFrame(np.quantile(trace4.gamma, quantiles, axis=0).T[0],\n",
    "                              columns=quantiles, index=counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(gamma_dist_prd[0.5], gamma_dist_obs[0.5])\n",
    "plt.vlines(gamma_dist_prd[0.5], gamma_dist_obs[0.25], gamma_dist_obs[0.75], lw=0.5)\n",
    "plt.hlines(gamma_dist_obs[0.5], gamma_dist_prd[0.25], gamma_dist_prd[0.75], lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County-level random slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random slope without pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "_u = d[['state_county', 'county_uranium']].drop_duplicates()\n",
    "_u['state_county'] = _u.state_county.map(lambda x: 'state_county[' + x + ']')\n",
    "_u = _u.set_index('state_county')\n",
    "_u = _u.loc[x2.columns]\n",
    "u = patsy.dmatrix('county_uranium', data=_u, return_type='dataframe')\n",
    "r3 = u.shape[1]\n",
    "\n",
    "x1x2 = pd.DataFrame(x1.values * x2.values,\n",
    "                    index=x1.index,\n",
    "                    columns=x2.columns + ':' + 'is_basement[T.True]')\n",
    "\n",
    "assert np.all(u.index == x2.columns)\n",
    "\n",
    "\n",
    "with pm.Model() as model5:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    \n",
    "    gamma_hyper_beta = pm.Normal('gamma_hyper_beta', sd=10, shape=(r3, 1))\n",
    "    gamma_hyper_mu = pm.Deterministic('gamma_hyper_mu', tt.dot(u.values, gamma_hyper_beta))\n",
    "    gamma_hyper_sd = pm.HalfCauchy('gamma_hyper_sd', beta=2)\n",
    "    gamma_ = pm.Normal('gamma_', shape=(r2, 1))\n",
    "    gamma = pm.Deterministic('gamma', gamma_hyper_mu + gamma_ * gamma_hyper_sd)\n",
    "    \n",
    "    kappa = pm.Normal('kappa', sd=10, shape=(r2, 1))\n",
    "    \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma) + tt.dot(x1x2.values, kappa)\n",
    "\n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    nu = pm.HalfCauchy('nu', beta=2)\n",
    "    obs = pm.StudentT('obs', mu=mu, sigma=sigma, nu=nu, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model5:\n",
    "    trace5 = pm.sample(tune=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace5, var_names=['beta',\n",
    "                                'gamma_hyper_beta', 'gamma_hyper_sd',\n",
    "                                'sigma', 'nu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace5, var_names=['kappa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -200\n",
    "\n",
    "mu_expect5 = mu.eval({getattr(model5, k.name): trace5[i][k.name]\n",
    "                      for k in model5.vars\n",
    "                      if k.name not in ['sigma_log__', 'nu_log__']})\n",
    "plt.scatter(mu_expect5, y.values, s=2)\n",
    "plt.plot([0, 2], [0, 2], color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(trace5['gamma_hyper_beta'][:,0,0],\n",
    "            trace5['gamma_hyper_beta'][:,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random slope with partial pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "_u = d[['state_county', 'county_uranium']].drop_duplicates()\n",
    "_u['state_county'] = _u.state_county.map(lambda x: 'state_county[' + x + ']')\n",
    "_u = _u.set_index('state_county')\n",
    "_u = _u.loc[x2.columns]\n",
    "u = patsy.dmatrix('county_uranium', data=_u, return_type='dataframe')\n",
    "r3 = u.shape[1]\n",
    "\n",
    "x1x2 = pd.DataFrame(x1.values * x2.values,\n",
    "                    index=x1.index,\n",
    "                    columns=x2.columns + ':' + 'is_basement[T.True]')\n",
    "\n",
    "assert np.all(u.index == x2.columns)\n",
    "\n",
    "with pm.Model() as model6:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    \n",
    "    gamma_hyper_beta = pm.Normal('gamma_hyper_beta', sd=10, shape=(r3, 1))\n",
    "    gamma_hyper_mu = pm.Deterministic('gamma_hyper_mu', tt.dot(u.values, gamma_hyper_beta))\n",
    "    gamma_hyper_sd = pm.HalfCauchy('gamma_hyper_sd', beta=2)\n",
    "    gamma_ = pm.Normal('gamma_', shape=(r2, 1))\n",
    "    gamma = pm.Deterministic('gamma', gamma_hyper_mu + gamma_ * gamma_hyper_sd)\n",
    "    \n",
    "    kappa_hyper_sd = pm.HalfCauchy('kappa_hyper_sd', beta=2)\n",
    "    kappa_ = pm.Normal('kappa_', shape=(r2, 1))\n",
    "    kappa = pm.Deterministic('kappa', kappa_ * kappa_hyper_sd)\n",
    "    \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma) + tt.dot(x1x2.values, kappa)\n",
    "\n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    nu = pm.HalfCauchy('nu', beta=2)\n",
    "    obs = pm.StudentT('obs', mu=mu, sigma=sigma, nu=nu, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model6:\n",
    "    trace6 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace6, var_names=['beta',\n",
    "                                'gamma_hyper_beta', 'gamma_hyper_sd',\n",
    "                                'kappa_hyper_sd', 'nu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace6, var_names=['kappa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random slope with a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x1 = patsy.dmatrices('log_radon ~ is_basement', data=d, return_type='dataframe')\n",
    "x1.drop(columns=['Intercept'], inplace=True)\n",
    "n, r1 = x1.shape\n",
    "\n",
    "x2 = patsy.dmatrix('state_county - 1', data=d, return_type='dataframe')\n",
    "r2 = x2.shape[1]\n",
    "\n",
    "_u = d[['state_county', 'county_uranium']].drop_duplicates()\n",
    "_u['state_county'] = _u.state_county.map(lambda x: 'state_county[' + x + ']')\n",
    "_u = _u.set_index('state_county')\n",
    "_u = _u.loc[x2.columns]\n",
    "u = patsy.dmatrix('county_uranium', data=_u, return_type='dataframe')\n",
    "r3 = u.shape[1]\n",
    "\n",
    "u_ni = patsy.dmatrix('county_uranium - 1', data=_u, return_type='dataframe')\n",
    "r4 = u_ni.shape[1]\n",
    "\n",
    "x1x2 = pd.DataFrame(x1.values * x2.values,\n",
    "                    index=x1.index,\n",
    "                    columns=x2.columns + ':' + 'is_basement[T.True]')\n",
    "\n",
    "assert np.all(u.index == x2.columns)\n",
    "\n",
    "with pm.Model() as model7:\n",
    "    beta = pm.Normal('beta', sd=10, shape=(r1, 1))\n",
    "    \n",
    "    gamma_hyper_beta = pm.Normal('gamma_hyper_beta', sd=10, shape=(r3, 1))\n",
    "    gamma_hyper_mu = pm.Deterministic('gamma_hyper_mu', tt.dot(u.values, gamma_hyper_beta))\n",
    "    gamma_hyper_sd = pm.HalfCauchy('gamma_hyper_sd', beta=2)\n",
    "    gamma_ = pm.Normal('gamma_', shape=(r2, 1))\n",
    "    gamma = pm.Deterministic('gamma', gamma_hyper_mu + gamma_ * gamma_hyper_sd)\n",
    "    \n",
    "    kappa_hyper_beta = pm.Normal('kappa_hyper_beta', sd=10, shape=(r4, 1))\n",
    "    kappa_hyper_mu = pm.Deterministic('kappa_hyper_mu', tt.dot(u_ni.values, kappa_hyper_beta))\n",
    "    kappa_hyper_sd = pm.HalfCauchy('kappa_hyper_sd', beta=2)\n",
    "    kappa_ = pm.Normal('kappa_', shape=(r2, 1))\n",
    "    kappa = pm.Deterministic('kappa', kappa_hyper_mu + kappa_ * kappa_hyper_sd)\n",
    "    \n",
    "    mu = tt.dot(x1.values, beta) + tt.dot(x2.values, gamma) + tt.dot(x1x2.values, kappa)\n",
    "\n",
    "    sigma = pm.HalfCauchy('sigma', beta=2)\n",
    "    nu = pm.HalfCauchy('nu', beta=2)\n",
    "    obs = pm.StudentT('obs', mu=mu, sigma=sigma, nu=nu, observed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model7:\n",
    "    trace7 = pm.sample(tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace7, var_names=['beta',\n",
    "                                'gamma_hyper_beta', 'gamma_hyper_sd',\n",
    "                                'kappa_hyper_beta', 'kappa_hyper_sd',\n",
    "                                'sigma', 'nu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace7, var_names=['kappa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model7:\n",
    "    ppc7 = pd.DataFrame(pm.sample_posterior_predictive(trace7, samples=1)['obs'][0],\n",
    "                        index=y.index, columns=y.columns)\n",
    "    \n",
    "plt.scatter(ppc7.log_radon, y.log_radon, s=2)\n",
    "plt.plot([-1, 4], [-1, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "                     ('complete_pooling_normal', model_classic, trace_classic),\n",
    "                     ('complete_pooling', model0, trace0),\n",
    "                     ('no_pooling', model1, trace1),\n",
    "                     ('partial_pooling', model2, trace2),\n",
    "                     ('partial_pooling_reparam', model3, trace3),\n",
    "                     ('county_uranium', model4, trace4),\n",
    "                     ('county_uranium_no_pooling_slope', model5, trace5),\n",
    "                     ('county_uranium_partial_pooling_slope', model6, trace6),\n",
    "                     ('county_uranium_both', model7, trace7),\n",
    "         ]\n",
    "\n",
    "\n",
    "\n",
    "model_compare = pm.compare({x[1]: x[2] for x in models}, ic='WAIC')\n",
    "model_compare.rename(index={i: x[0] for i, x in enumerate(models)}, inplace=True)\n",
    "pm.compareplot(model_compare, figsize=(15, 5))\n",
    "plt.legend()\n",
    "\n",
    "model_compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "145px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}